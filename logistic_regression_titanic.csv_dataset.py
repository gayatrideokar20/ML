# -*- coding: utf-8 -*-
"""Logistic Regression.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eI2p85qwxcX_0nf-WDcXxNZB3e_eRVUA
"""

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

data=pd.read_csv('titanic.csv')


#Analyze data
#sns.countplot(x='Survived',data=data)
#sns.countplot(x='Survived',hue='Sex',data=data)
#data['Age'].plot.hist()
#data['Fare'].plot.hist()



#Data wrangling or cleaning
#data.isnull()
#data.isnull().sum()
#cleaning nan values by droping that colums
#data.drop('Cabin',axis=1,inplace=True)
#cleaning nan values ie removing rows with nan values instead of droping colums
data.dropna(inplace=True)
#data.isnull()
data.head(5)
#putting categorical values 0/1 where there isnt like Sex embarkked
Sex=pd.get_dummies(data['Sex'],drop_first=True)
#sex.head(5)
Embarked=pd.get_dummies(data['Embarked'],drop_first=True)
Pcl=pd.get_dummies(data['Pclass'],drop_first=True)

#concatenate all these new into data
data=pd.concat([data,Sex,Embarked,Pcl],axis=1)


#drop pure string colums and ubove ones too
data.drop(['PassengerId','Name','Sex','Ticket','Pclass','Cabin','Embarked'],axis=1,inplace=True)
data.head()


#train and test here target y is survided rest are features X
X=data.drop('Survived',axis=1)
y=data['Survived']


x_train, x_test, y_train, y_test=train_test_split(X,y,test_size=0.3,random_state=1)
reg1=LogisticRegression()

#incase we are working with large data we need to scale it 
#from sklearn.preprocessing import StandardScaler
#sc=StandardScaler()
#x_train=sc.fit_transform(x_train)
#x_test=sc.transform(x_test)

reg1.fit(x_train, y_train)
y_pred=reg1.predict(x_test)

print(accuracy_score(y_test,y_pred))